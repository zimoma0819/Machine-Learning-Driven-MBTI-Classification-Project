{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>['moment', 'sportscenter', 'top', 'ten', 'play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>['finding', 'lack', 'these', 'post', 'very', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>['good', 'one', 'course', 'which', 'say', 'kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>['dear', 'enjoyed', 'our', 'conversation', 'ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>['fired', 'another', 'silly', 'misconception',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>['because', 'always', 'think', 'cat', 'fi', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>['thread', 'already', 'exists', 'someplace', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>['many', 'question', 'when', 'these', 'thing',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>['very', 'conflicted', 'right', 'now', 'when',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>['been', 'too', 'long', 'since', 'been', 'pers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type                                              Posts\n",
       "0     INFJ  ['moment', 'sportscenter', 'top', 'ten', 'play...\n",
       "1     ENTP  ['finding', 'lack', 'these', 'post', 'very', '...\n",
       "2     INTP  ['good', 'one', 'course', 'which', 'say', 'kno...\n",
       "3     INTJ  ['dear', 'enjoyed', 'our', 'conversation', 'ot...\n",
       "4     ENTJ  ['fired', 'another', 'silly', 'misconception',...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  ['because', 'always', 'think', 'cat', 'fi', 'd...\n",
       "8671  ENFP  ['thread', 'already', 'exists', 'someplace', '...\n",
       "8672  INTP  ['many', 'question', 'when', 'these', 'thing',...\n",
       "8673  INFP  ['very', 'conflicted', 'right', 'now', 'when',...\n",
       "8674  INFP  ['been', 'too', 'long', 'since', 'been', 'pers...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df = pd.read_csv('./processed_mbti.csv', header = 0)\n",
    "mbti_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = mbti_df['Posts']\n",
    "y_data = mbti_df['Type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> <h2>Vectorization</h2> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> <h2>L1 Logistic Regression</h2> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4917402996542451"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_clf1 = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=1.0).fit(X_train_vectorized, y_train)\n",
    "l1_clf1.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5197848636189013"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_clf2 = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=2.0).fit(X_train_vectorized, y_train)\n",
    "l1_clf2.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5194006915097964"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_clf3 = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=1.9).fit(X_train_vectorized, y_train)\n",
    "l1_clf3.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5209373799462159"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_clf7 = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=1.8).fit(X_train_vectorized, y_train)\n",
    "l1_clf7.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5224740683826354"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_clf8 = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=2.5).fit(X_train_vectorized, y_train)\n",
    "l1_clf8.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> <h3>Evaluation<h3></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For L1 penalty and using the solver 'liblinear', the score for logistic regression model is the highest (0.67960) when C = 1.9. \n",
    "- When C is greater or smaller than 1.9, the score is lower. Even there is just a 0.1 difference in the value of C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='lightblue'> <h3>Let's try to change solver to 'saga' (another solver left that works for L1):</h3> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5113330772185939"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_clf4 = LogisticRegression(random_state=0, solver='saga', penalty='l1', C=2.0, max_iter=10000).fit(X_train_vectorized, y_train)\n",
    "l1_clf4.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5132539377641183"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_clf5 = LogisticRegression(random_state=0, solver='saga', penalty='l1', C=1.5, max_iter=10000).fit(X_train_vectorized, y_train)\n",
    "l1_clf5.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5021129466000769"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_clf5 = LogisticRegression(random_state=0, solver='saga', penalty='l1', C=1.0, max_iter=10000).fit(X_train_vectorized, y_train)\n",
    "l1_clf5.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4994237418363427"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_clf6 = LogisticRegression(random_state=0, solver='saga', penalty='l1', C=0.9, max_iter=10000).fit(X_train_vectorized, y_train)\n",
    "l1_clf6.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> <h3>Evaluation<h3></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For L1 penalty and using the solver 'saga', the score for logistic regression model is the highest (0.68037) when C = 1.0.\n",
    "- The score decreases when I either move up or down even just 0.1.\n",
    "\n",
    "Compare to what I got from using the solver 'liblinear' with C = 1.9 (score = 0.67960), model with 'saga' and C = 1.0 has slightly better performance, and it has the best performance among all combo of parameters I have tried today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> <h2>L2 Logistic Regression</h2> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46753745678063774"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_clf1 = LogisticRegression(random_state=0, solver='liblinear', penalty='l2', C=1.0).fit(X_train_vectorized, y_train)\n",
    "l2_clf1.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4932769880906646"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_clf2 = LogisticRegression(random_state=0, solver='liblinear', penalty='l2', C=2.0).fit(X_train_vectorized, y_train)\n",
    "l2_clf2.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5009604302727622"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_clf3 = LogisticRegression(random_state=0, solver='liblinear', penalty='l2', C=3.0).fit(X_train_vectorized, y_train)\n",
    "l2_clf3.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5086438724548598"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_clf4 = LogisticRegression(random_state=0, solver='liblinear', penalty='l2', C=5.0).fit(X_train_vectorized, y_train)\n",
    "l2_clf4.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5082597003457549"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_clf5 = LogisticRegression(random_state=0, solver='liblinear', penalty='l2', C=5.1).fit(X_train_vectorized, y_train)\n",
    "l2_clf5.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> <h3>Evaluation<h3></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For L2 penalty and using the solver 'liblinear', the score for logistic regression model is the highest (0.65617) when C = 5.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> <h3>Try Other Solvers (Here only shows the model with best performance in different solvers) <h3></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50787552823665"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_clf6 = LogisticRegression(random_state=0, solver='lbfgs', penalty='l2', C=3.7, max_iter = 1000).fit(X_train_vectorized, y_train)\n",
    "l2_clf6.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For solver 'lbfgs', the best performance score is 0.656550 at C = 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.504802151363811"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_clf7 = LogisticRegression(random_state=0, solver='newton-cg', penalty='l2', C=3.0, max_iter = 1000).fit(X_train_vectorized, y_train)\n",
    "l2_clf7.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For solver 'newton-cg', the best performance score is 0.656934 at C = 3.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49980791394544755"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_clf8 = LogisticRegression(random_state=0, solver='saga', penalty='l2', C=2.4, max_iter = 1000).fit(X_train_vectorized, y_train)\n",
    "l2_clf8.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For solver 'saga', the best performance score is 0.656550 at C = 2.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.504802151363811"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_clf9 = LogisticRegression(random_state=0, solver='sag', penalty='l2', C=3.0, max_iter = 1000).fit(X_train_vectorized, y_train)\n",
    "l2_clf9.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For solver 'sag', the best performance score is 0.656934 at C = 3.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l2_clf10 = LogisticRegression(random_state=0, solver='newton-cholesky', penalty='l2', C=3.0, max_iter = 1000).fit(X_train_vectorized, y_train)\n",
    "# l2_clf10.score(X_test_vectorized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For solver 'newton-cholesky', the model cost too long to implement so there is no score for this one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lightblue'> <h3>Evaluation<h3></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All in all, for L2, the models with best performance (0.656934) have parameters (solver='newton-cg', C = 3.0) or (solver='sag', C = 2.7). \n",
    "- Compare to the best model using L1, model with L1 and parameters (solver = 'saga', C = 1.0) has better performance at score = 0.68037. \n",
    "- According to the coefficients checking below, model with l1 regularization has a lot of 0-value coefficients, referring to that L1 penalty has ability to drive some coefficients to 0 and perform feature selection. Thus, the model is easier to interpret. Unlike L1, L2 cannot perform feature selection. All the coefficients are non-zero, making the model more complex and harder to interpret. \n",
    "- When I was playing around with different C-value and solvers, in both L1 and L2, I encountered convergence issue, thus it's hard to define which regularization is more likely to have such issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_clf5.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.39857862e-02,  1.12159855e-01, -2.98069890e-03, ...,\n",
       "        -1.17238823e-02, -5.07653395e-04, -3.83207798e-03],\n",
       "       [-1.10433832e-01,  4.51155639e-01, -7.91610365e-03, ...,\n",
       "         1.62640620e-01, -3.36453371e-03, -2.25928212e-02],\n",
       "       [ 1.99060476e-01,  3.46716726e-01, -4.98020077e-03, ...,\n",
       "        -2.97072827e-03, -7.29894239e-04, -8.68032675e-03],\n",
       "       ...,\n",
       "       [ 7.58923816e-01, -3.08842907e-01,  2.06115233e-01, ...,\n",
       "        -1.63131356e-02, -2.55231794e-03, -5.82909784e-03],\n",
       "       [-2.40358148e-01, -2.01293536e-01, -8.14025976e-03, ...,\n",
       "        -4.88366130e-03, -1.44182025e-03, -6.77584810e-03],\n",
       "       [-1.90118801e-01, -4.79191086e-01, -1.25699046e-02, ...,\n",
       "        -1.18530056e-02, -4.39622404e-03, -6.27113388e-03]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_clf9.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
